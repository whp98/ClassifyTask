#第13组实验报告
##实验过程
1.选取分类方法  

为了更好的分类我们先后使用了贝叶斯算法和支持向量机算法算法，在pac降维后我们得出支持向量机算法更加适合本实验，
因为在相同的维数下支持向量机得到了更好的结果  

2.使用全部特征值进行分类

这个过程比较简单，先将数据按照libsvm要求的格式存储到all.txt中然后使用自带的工具来进行归一化，使用svm读取label和特征。最后训练模型然后预测。  


3.计算留一交叉验证方法的分类误差作为基值  

对于每一个数据行所在的行，使用numpy的删除方法，得到除去验证数据的训练数据，使用剩余数据进行模型训练，然后等待训练结束后，使用svm模型对这一行数据进行预测，然后将该组数据的预测结果存储到一个list中。  
然后将list中的数据计算平均值，最后返回数据的误差的百分比数值。  

4.选择并设计降维方法

我们这里先后使用了方差降维和pca降维，经过实验验证pac降维效果更加好，能够在高准确的情况下将数据降低到个位数的维度，实在是太妙了所以，最终代码里面包含了方差降维，但是不会使用方差降维  
最终方案是SVM+PCA来解决问题

5.得出降维后的分类误差并且与基值做比较  
    原视数据得出的baseline值是3.55329949238579  
    降低到100维 loss=7.614213197969548  
    降低到50维 loss=5.583756345177662  
    减低到10维 loss=3.55329949238579  
    降低到6维达到最优值 loss=1.5228426395939039


##实验参数
运行环境：pyhon版本3.7
##需配置参数
#### 降维的维度

```weidu = 10```

 #### 中间文件的名称

```tempfilename = "all.txt"```

#### 是否使用pca降维

```usepca = False``` 



##计算结果


|维数（pca降维）|留一交叉验证误差（%）|
|---|---|
|3312(原始)|3.55329949238579|
|降至100维 |7.614213197969548|
|降至50维| 5.583756345177662|
|降至10维|3.55329949238579|
|降至6维|1.5228426395939039|

